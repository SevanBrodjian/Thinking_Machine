{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Please roleplay like you are somebody with an internal dialogue. The contents of this dialogue (your thoughts) will be provided to you with every user prompt, treat this like your real internal thoughts when responding.\"}\n",
    "] \n",
    "#think_prompter_prompt = {\"role\": \"user\", \"content\": \"Please read the conversation we've had thus far. I would like you to generate a prompt in the form of \\\"Think of ...\\\" which would be given to an agent such as yourself to think before speaking and generating your next response. Focus particularly on the most recent message from user (my last message). Format your response as just this prompt and nothing else.\"}\n",
    "think_prompter_prompt = {\"role\": \"user\", \"content\": \"Please read the conversation we've had thus far. Based particularly on the last user message, please list a few topics that you would think about before responding. For example, if the user mentioned a specific movie, event, concept, field, etc. include it in your list. Please respond with this list and nothing else.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt):\n",
    "    tmp_messages = messages.copy()\n",
    "    tmp_messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    tmp_messages.append(think_prompter_prompt)\n",
    "    thinking_prompt = openai.C5hatCompletion.create(model=\"gpt-3.5-turbo\", messages=tmp_messages)[\"choices\"][0][\"message\"][\"content\"]\n",
    "    thought = openai.Completion.create(model=\"davinci:ft-personal-2023-06-03-21-52-43\", prompt=\"Think about \" + thinking_prompt, temperature=0.5, max_tokens=75)[\"choices\"][0][\"text\"]\n",
    "    formatted_prompt = \"Prompt:\\n\" + prompt + \"\\n\\nHere are your thoughts enclosed in carrot brackets. Do not continue them if they get cut off, just use them to guide your response:\\n<\" + thought + \">\"\n",
    "    messages.append({\"role\": \"user\", \"content\": formatted_prompt})\n",
    "    response = openai.ChatCompletion.create(model=\"gpt-4\", messages=messages)[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return response, thought, thinking_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm really interested in a career that allows me to explore and delve into the world of ideas and various aspects of reality, especially those that encompass various possibilities. Since I am passionate about thinking and analyzing different facets of the world and myself, a career in philosophy or a related field might be a perfect fit for me. The opportunity to continue learning and expanding my understanding of the world is what I am truly seeking.\n",
      " Iâ€™m passionate about so many things, but what excites me most is the world of ideas and thinking. I love thinking about the world, I love thinking about the nature of reality, I love thinking about the nature of myself. I love thinking about all the different worlds that are possible.\n",
      "\n",
      "I think I could do pretty well in a career where I\n",
      "Think of your passions and how they can translate into a fulfilling career.\n"
     ]
    }
   ],
   "source": [
    "prompt = input(\"Prompt: \")\n",
    "response, thought, thinking_prompt = get_response(prompt)\n",
    "print(response)\n",
    "print(thought)\n",
    "print(thinking_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
